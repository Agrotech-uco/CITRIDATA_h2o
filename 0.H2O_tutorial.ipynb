{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es un tutorial de instalación de la libreria de H2O.ai.\n",
    "\n",
    "Tambien incluye una pequeña guia con los primeros pasos (ETL) que se deben hacer para echar a funcionar la libreria asi como una prueba con distintos modelos que incluye H2O.\n",
    "\n",
    "> Pedro Juan Torres González\n",
    "> > Última version: 7-02-2025 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Instalación $H_2O$.ai \n",
    "\n",
    "* Para desarrollar con Python un modelo predictivo basado en \"h2o\" necesitamos un cluster de servidores (al menos UNO) en localhost.\n",
    "\n",
    "La opción mas rápida por el momento sin necesidad de crear una imagen docker, es ejecutarlo directamente en la máquina local, esto ofrece un servicio de acceso a través de http://localhost:54321 que se incluye en un momento determinado en el script de python que crearemos para entrenar el modelo; Para llegar hasta aquí necesitamos instalar JAVA (versión máxima 17, solo con el runtime es suficiente) y el servidor de h2o.\n",
    "\n",
    "\n",
    "**Documentación**\n",
    "\n",
    "> https://docs.h2o.ai/\n",
    "\n",
    "> https://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html\n",
    "\n",
    "> https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/getting-started/python-users.rst\n",
    "\n",
    "> https://github.com/SeanPLeary/time-series-h2o-automl-example/blob/master/h2o_automl_example_with_multivariate_time_series.ipynb\n",
    "\n",
    "\n",
    "> Time Series: https://h2o.ai/blog/2021/an-introduction-to-time-series-modeling-time-series-preprocessing-and-feature-engineering/\n",
    "\n",
    "> Time Series: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-success\">\n",
    " Recomendado instalarlo en la máquina virtual desplegada en voneclod de la UCO. Así, siguiendo estas instrucciones nos funcionaría a todos.\n",
    " <div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Despliegue servidor H2O (VoneCloud)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **INSTALACION DE JAVA EN UBUNTU 22.04** (template atdfiware-template)\n",
    "\n",
    "    * sudo apt install openjdk-17-jre-headless\n",
    "\n",
    "2. **INSTALACION DE H2O SERVER**\n",
    "\n",
    "    * Crear, donde os interese, un directorio aparte para este trabajo **mkdir serverh2o** y cambiarse a el **cd serverh2o**.\n",
    "    * Descargar \"h2o.io\" desde ahí, con la siguiente instrucción: **wget https://h2o-release.s3.amazonaws.com/h2o/rel-3.46.0/6/h2o-3.46.0.6.zip**.\n",
    "    * Descomprimir el archivo: **unzip h2o-3.46.0.6.zip**, creará un nuevo directorio, cambiarse a él **cd h2o-3.46.0.6**\n",
    "    * Iniciar el servidor: **java -jar h2o.jar** (dejarlo estar) y abrir otro shell de comandos para trabajar.\n",
    "\n",
    "Con esto podemos crear el escript y probar pero siempre desde esa máquina, para poder hacer referencia al \"localhost\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> ATENCION: OTRO NIVEL.\n",
    "\n",
    "Ejecución/desarrollo del script deseado que use H2O (nuestro servidor desplegado en vonecloud), pero desde nuestro ordenador (por si os resulta mas cómodo), es decir: trabajo en el Python de mi máquina, pero uso la librería/servidor de h2o desplegado en la máquina \"vonecloud\" (siempre desde la UCO o con VPN)\n",
    "<div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión al Servidor desde maquina externa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto debería de funcionar cuando en mi script de Python tenga que hacer referencia al servidor, mediante su nombre de dominio, esto es: **\"http://NOMBRE_MAQUINA.cloud.uco.es:5432\"** o bien con su IP (pero NO funciona). \n",
    "> Para esto hay que crear/abrir un \"tunnel ssh\" en nuestra máquina local asignando un puerto local y entonces si funcionaría.\n",
    "\n",
    "* El tunnel ssh se crea desde mi máquina local (mi PC), así:\n",
    "\n",
    "    * **ssh -L 55554:localhost:54321 usuario@NOMBRE_MAQUINA.cloud.uco.es**\n",
    "\n",
    "de esta forma en el script de Python en mi máquina local accedería como (http://localhost:55554) y redireccionaría al servidor de vonecloud.\n",
    "\n",
    "INTERESANTE: este servidor de h2o local en nuestra máquina tiene un entorno para desarrollar accesible, con el \"tunnel ssh\" a través de la URL: http://localhost:55554/flow/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya tendriamos el servidor corriendo y la conexión desde nuestra maquina a este."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación desde Docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es tener instalado docker en tu equipo.\n",
    "\n",
    "1. Descargar los archivos : https://drive.google.com/file/d/1z_ruejueM-UgqKQOCUngK4hsBECycwFE/view?usp=sharing\n",
    "\n",
    "1. Descomprimir, mover la carpeta h2o al directorio donde tienes los docker, entrar\n",
    "1. 'docker compose up' para iniciar docker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros Pasos H2O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero sera descargar el paquete de python de H2O en nuestra maquina local para poder trabajar. \n",
    "\n",
    "* pip install h2o\n",
    "\n",
    "Tras tenerlo instalado ya podemos conectarnos al servidor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONEXIONES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
      "Warning: Your H2O cluster version is (3 months and 12 days) old.  There may be a newer version available.\n",
      "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 min 09 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 12 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>root</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.807 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 min 09 secs\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    3 months and 12 days\n",
       "H2O_cluster_name:           root\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.807 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.12 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 min 09 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>3 months and 12 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>root</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.807 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 min 09 secs\n",
       "H2O_cluster_timezone:       UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    3 months and 12 days\n",
       "H2O_cluster_name:           root\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.807 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.12 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###################################################\n",
    "# C O N E X I O N   A L   C L U S T E R   H 2 O   #\n",
    "###################################################\n",
    "\n",
    "import h2o\n",
    "\n",
    "# Realizamos la conexion a nuestro puerto conectado con el servidor mediante el tunel SSH\n",
    "h2o.init(url=\"http://localhost:54321\")\n",
    "\n",
    "# Mostramos el estado del cluster\n",
    "h2o.cluster().show_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "Conexión Realizada, ahora debemos acceder a los datos en CrateDB para empezar a hacer ML.\n",
    "Para conectarnos a CrateDB de nuestro servidor Primero, debemos asegurarnos de que CrateDB esté configurado para aceptar conexiones desde la máquina local (ya sea a través de un túnel SSH o directamente si el puerto está expuesto). El puerto por defecto de CrateDB es 4200. En nuestro caso el puerto está abierto y deberiamos poder conectarnos mediante la url: http://NOMBRE_MAQUINA.cloud.uco.es:4200\n",
    "\n",
    "Para instalar la libreria de Crate:\n",
    "* Pip install crate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas disponibles: [['etestacion_meteo'], ['md_ets_metadata']]\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "# C O N E X I O N   C O N   C R A T E D B  #\n",
    "############################################\n",
    "from crate import client\n",
    "\n",
    "#HOST_CRATE=\"http://atd-z32togop.cloud.uco.es:4200\" #CAMBIAR SEGUN LA IP DE TU SERVIDOR\n",
    "HOST_CRATE=\"http://localhost:4200\"\n",
    "# Conectamos con CrateDB\n",
    "connection = client.connect(HOST_CRATE, username=\"crate\")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Consultamos las tablas existentes en CrateDB\n",
    "cursor.execute(\"SHOW TABLES\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Tablas disponibles:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crate import client\n",
    "import pandas as pd\n",
    "\n",
    "def query_to_dataframe(crate_host, query, username=\"crate\"):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta en CrateDB y devuelve los resultados como un DataFrame de pandas.\n",
    "\n",
    "    :param crate_host: Dirección del servidor CrateDB (por ejemplo, \"http://localhost:4200/\")\n",
    "    :param query: Consulta SQL a ejecutar\n",
    "    :param username: Usuario para la conexión (por defecto \"crate\")\n",
    "    :return: pandas DataFrame con los resultados de la consulta\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Conexión a CrateDB\n",
    "        connection = client.connect(crate_host, username=username)\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Ejecutar la consulta\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Obtener las columnas de la consulta\n",
    "        columns = [col[0] for col in cursor.description]\n",
    "\n",
    "        # Obtener los resultados de la consulta\n",
    "        data = cursor.fetchall()\n",
    "\n",
    "        # Convertir los resultados a un DataFrame de pandas\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "        # Cerrar la conexión\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error en la consulta:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       entity_id          time_index   no2  so2      o3    pm10    pm25\n",
      "0  COCOR_LEPANTO 2021-10-25 01:00:00  41.0  5.0  54.125  26.362   9.833\n",
      "1  COCOR_LEPANTO 2021-10-25 02:00:00  25.0  5.0  45.000  26.362   9.875\n",
      "2  COCOR_LEPANTO 2021-10-25 03:00:00  17.0  5.0  37.875  26.552  10.000\n",
      "3  COCOR_LEPANTO 2021-10-25 04:00:00  11.0  5.0  34.000  26.505  10.125\n",
      "4  COCOR_LEPANTO 2021-10-25 05:00:00  10.0  5.0  32.500  26.268  10.125 \n",
      "\n",
      "Dimension df: (28571, 7) \n",
      "\n",
      "Tipos de datos de las columnas:\n",
      " entity_id             object\n",
      "time_index    datetime64[ns]\n",
      "no2                  float64\n",
      "so2                  float64\n",
      "o3                   float64\n",
      "pm10                 float64\n",
      "pm25                 float64\n",
      "dtype: object\n",
      "\n",
      "Valores nulos por columna:\n",
      " entity_id       0\n",
      "time_index      0\n",
      "no2           448\n",
      "so2           868\n",
      "o3            279\n",
      "pm10          247\n",
      "pm25          269\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# D E S C A R G A   D E   D A T O S  #\n",
    "######################################\n",
    "\n",
    "\n",
    "query= \"\"\" \n",
    "SELECT entity_id, time_index, no2, so2, o3, pm10, pm25\n",
    "FROM \"mtatdfiware\".\"etestacion_meteo\"\n",
    "WHERE entity_id LIKE 'COCOR_LEPANTO'\n",
    "ORDER BY time_index\"\"\" # Esta consulta es la misma que hacemos en el portal de crate para buscar cierta tabla, en este ejemplo vamos a trabajar con los datos de COCOR_LEPANTO\n",
    "cursor.execute(query)\n",
    "\n",
    "df=query_to_dataframe(HOST_CRATE, query,\"crate\")\n",
    "df[\"time_index\"]=pd.to_datetime(df[\"time_index\"], unit='ms')\n",
    "print(df.head(),\"\\n\")\n",
    "print(\"Dimension df:\", df.shape,\"\\n\")\n",
    "print(\"Tipos de datos de las columnas:\\n\",df.dtypes)\n",
    "print(\"\\nValores nulos por columna:\\n\",df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto ya podemos empezar a procesar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROCESAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta puede que sea la parte más importante del proceso de crear un modelo matemático, debemos arreglar los datos para que el modelo se entrene correctamente. Para este caso, vamos a hacer un procesamiento muy basico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "La idea que he tenido es la siguiente:\n",
    "\n",
    "* Partiendo de la estructura del df, en la cual una cantidad variable de instancias por dia. Esto es debido a la forma de mandar los datos (actualizamos solo si hay cambios, luego tendremos para cada dia un numero de instancias distintas, en el mejor de los casos en cada hora habria cambiado un atributo y tendremos 24 instancias de ese dia ).\n",
    "* La solución que he pensado para esto ha sido pasar de un registro horario a uno diario, por tanto vamos a crear un nuevo dataframe formado solo por **las medias diarias** de los atributos a inferir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date        no2       so2         o3       pm10       pm25\n",
      "0  2021-10-25  16.260870  5.086957  51.581522  26.511174  10.088739\n",
      "1  2021-10-26  24.583333  5.083333  45.864583  31.662792  10.678833\n",
      "2  2021-10-27  22.125000  5.041667  50.010417  34.898667  12.168375\n",
      "3  2021-10-28  21.708333  5.000000  47.458333  28.735708  10.220500\n",
      "4  2021-10-29  21.291667  5.083333  44.546458  37.754542  14.005083\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Convertir 'time_index' a formato datetime\n",
    "df['date'] = pd.to_datetime(df['time_index'], unit='ms').dt.date\n",
    "df.drop('entity_id', axis=1, inplace=True)\n",
    "\n",
    "# Calcular la media diaria para cada atributo\n",
    "df_daily = df.groupby(['date']).agg({\n",
    "    'no2': 'mean',\n",
    "    'so2': 'mean',\n",
    "    'o3': 'mean',\n",
    "    'pm10': 'mean',\n",
    "    'pm25': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# # Normalizamos los datos\n",
    "# scaler = MinMaxScaler()\n",
    "# df_daily[['no2', 'so2', 'o3', 'pm10', 'pm25']] = scaler.fit_transform(df_daily[['no2', 'so2', 'o3', 'pm10', 'pm25']])\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_daily.head())\n",
    "\n",
    "#Subimos el dataframe a H2O con el nombre COCOR_LEPANTO_avg\n",
    "\n",
    "hf = h2o.H2OFrame(df_daily, destination_frame=\"COCOR_LEPANTO_avg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuardamos el csv\n",
    "df_daily.to_csv(\"datos_diarios_COCOR_LEPANTO.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Para trabajar con series temporales debemos crear un **dataframe \"Laggeado\"** esto es un dataframe al que hemos añadido los valores anteriores como nuevos atributos para que se tengan en cuenta al crear el modelo predictivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date        no2       so2         o3       pm10       pm25  \\\n",
      "0  2022-10-07  17.368421  2.315789  56.697368  47.145789  15.146789   \n",
      "1  2022-10-08  11.600000  2.400000  56.875000  47.685000  14.778200   \n",
      "2  2022-10-09   6.666667  2.066667  71.841667  50.328000  15.599667   \n",
      "3  2022-10-10   9.117647  2.000000  69.669118  53.290588  15.286824   \n",
      "4  2022-10-11  15.923077  2.076923  52.557692  35.352692  13.066692   \n",
      "\n",
      "   so2_lag_1   o3_lag_1  pm10_lag_1  pm25_lag_1  so2_lag_2   o3_lag_2  \\\n",
      "0   2.200000  65.658333   89.976000   27.100733   2.928571  46.776786   \n",
      "1   2.315789  56.697368   47.145789   15.146789   2.200000  65.658333   \n",
      "2   2.400000  56.875000   47.685000   14.778200   2.315789  56.697368   \n",
      "3   2.066667  71.841667   50.328000   15.599667   2.400000  56.875000   \n",
      "4   2.000000  69.669118   53.290588   15.286824   2.066667  71.841667   \n",
      "\n",
      "   pm10_lag_2  pm25_lag_2  so2_lag_3   o3_lag_3  pm10_lag_3  pm25_lag_3  \n",
      "0  114.084643   35.058857   2.800000  47.178923  107.449615   33.746615  \n",
      "1   89.976000   27.100733   2.928571  46.776786  114.084643   35.058857  \n",
      "2   47.145789   15.146789   2.200000  65.658333   89.976000   27.100733  \n",
      "3   47.685000   14.778200   2.315789  56.697368   47.145789   15.146789  \n",
      "4   50.328000   15.599667   2.400000  56.875000   47.685000   14.778200   \n",
      "\n",
      "Dimension df: (806, 18) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_lagged_features_daily(df, lags=1):\n",
    "    \"\"\"\n",
    "    Crea características de rezago a partir de un DataFrame de series temporales diarias.\n",
    "    :param df: DataFrame con medias diarias\n",
    "    :param lags: Número de lags a generar (por ejemplo, 1 para la observación anterior)\n",
    "    :return: DataFrame con características de rezago\n",
    "    \"\"\"\n",
    "    lagged_df = df.copy()\n",
    "\n",
    "    for lag in range(1, lags + 1):\n",
    "        for col in df.columns[2:]:  # Suponiendo que las columnas de interés son las de no2, so2, o3, etc.\n",
    "            lagged_df[f\"{col}_lag_{lag}\"] = lagged_df[col].shift(lag)\n",
    "    \n",
    "    # Eliminar filas con valores nulos (por desplazamiento)\n",
    "    lagged_df = lagged_df.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return lagged_df\n",
    "\n",
    "# Crear características de rezago\n",
    "lagged_df_daily = create_lagged_features_daily(df_daily, lags=3)\n",
    "lagged_df_daily=lagged_df_daily.sort_values(by=['date'],ascending=True) #ordenamos los datos por fecha para respetar la temporalidad de los datos\n",
    "\n",
    "# Mostrar el DataFrame con las nuevas características\n",
    "print(lagged_df_daily.head(),\"\\n\")\n",
    "print(\"Dimension df:\", lagged_df_daily.shape,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de entrenamiento: 644\n",
      "Tamaño de test: 162\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Datos X (Características): date                     so2       o3     pm10     pm25    so2_lag_1    o3_lag_1    pm10_lag_1    pm25_lag_1    so2_lag_2    o3_lag_2    pm10_lag_2    pm25_lag_2    so2_lag_3    o3_lag_3    pm10_lag_3    pm25_lag_3\n",
      "2022-10-07 00:00:00  2.31579  56.6974  47.1458  15.1468      2.2         65.6583       89.976        27.1007      2.92857     46.7768      114.085        35.0589      2.8         47.1789      107.45         33.7466\n",
      "2022-10-08 00:00:00  2.4      56.875   47.685   14.7782      2.31579     56.6974       47.1458       15.1468      2.2         65.6583       89.976        27.1007      2.92857     46.7768      114.085        35.0589\n",
      "2022-10-09 00:00:00  2.06667  71.8417  50.328   15.5997      2.4         56.875        47.685        14.7782      2.31579     56.6974       47.1458       15.1468      2.2         65.6583       89.976        27.1007\n",
      "2022-10-10 00:00:00  2        69.6691  53.2906  15.2868      2.06667     71.8417       50.328        15.5997      2.4         56.875        47.685        14.7782      2.31579     56.6974       47.1458       15.1468\n",
      "2022-10-11 00:00:00  2.07692  52.5577  35.3527  13.0667      2           69.6691       53.2906       15.2868      2.06667     71.8417       50.328        15.5997      2.4         56.875        47.685        14.7782\n",
      "2022-10-12 00:00:00  2.33333  58.7917  34.026   12.8023      2.07692     52.5577       35.3527       13.0667      2           69.6691       53.2906       15.2868      2.06667     71.8417       50.328        15.5997\n",
      "2022-10-13 00:00:00  2.66667  55.9     31.416   11.5863      2.33333     58.7917       34.026        12.8023      2.07692     52.5577       35.3527       13.0667      2           69.6691       53.2906       15.2868\n",
      "2022-10-14 00:00:00  2.90909  48.8864  29.5814  10.7205      2.66667     55.9          31.416        11.5863      2.33333     58.7917       34.026        12.8023      2.07692     52.5577       35.3527       13.0667\n",
      "2022-10-15 00:00:00  3.11765  53       33.8532  13.7019      2.90909     48.8864       29.5814       10.7205      2.66667     55.9          31.416        11.5863      2.33333     58.7917       34.026        12.8023\n",
      "2022-10-16 00:00:00  3        53.0729  42.2025  15.6054      3.11765     53            33.8532       13.7019      2.90909     48.8864       29.5814       10.7205      2.66667     55.9          31.416        11.5863\n",
      "[10 rows x 17 columns]\n",
      "\n",
      "Datos Y (Variable objetivo):      no2\n",
      "17.3684\n",
      "11.6\n",
      " 6.66667\n",
      " 9.11765\n",
      "15.9231\n",
      "10.6\n",
      "18.6\n",
      "24.3636\n",
      "19.9412\n",
      "15.6667\n",
      "[10 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#   TRAIN-TEST SPLIT   #\n",
    "########################\n",
    "\n",
    "# Dividir el DataFrame en conjuntos de entrenamiento y prueba.\n",
    "train_size = int(len(lagged_df_daily) * 0.8)\n",
    "#train_size = int(len(hf) * 0.8)\n",
    "print(\"Tamaño de entrenamiento:\", train_size)\n",
    "train_df = lagged_df_daily[:train_size]\n",
    "\n",
    "test_df = lagged_df_daily[train_size:]\n",
    "print(\"Tamaño de test:\", len(test_df))\n",
    "\n",
    "# Pasamos de pandas.df a h2o.df\n",
    "train_h2o = h2o.H2OFrame(train_df, destination_frame=\"COCOR_LEPANTO_lagged_avg_train\")\n",
    "test_h2o = h2o.H2OFrame(test_df, destination_frame=\"COCOR_LEPANTO_lagged_avg_test\")\n",
    "\n",
    "# Definir la variable objetivo\n",
    "target = 'no2'\n",
    "\n",
    "# Definir las variables predictoras (todas menos la variable objetivo)\n",
    "x = [col for col in train_h2o.columns if col != target]\n",
    "# Definir la variable objetivo (target)\n",
    "y = target\n",
    "\n",
    "# Obtener los datos de X e Y\n",
    "X_data = train_h2o[x]  # Datos de las características\n",
    "Y_data = train_h2o[y]  # Datos de la variable objetivo\n",
    "\n",
    "# Verificar la correcta asignación de X e Y\n",
    "print(\"Datos X (Características):\", X_data.head())\n",
    "print(\"Datos Y (Variable objetivo):\", Y_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a probar los distintos modelos que tiene H2O, como vamos a comparar modelos, es de **vital importancia** que las particiones (train,test) sean las mismas en cada prueba de cada modelo. Si no hacemos esto asi entonces los resultados **NO SON COMPARABLES**.\n",
    "\n",
    "\n",
    "En la prueba utilizaremos AutoML que realiza una comparación entre distintos modelos y elige el que tiene mejor resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2OAutoML` es una herramienta de aprendizaje automático que facilita la construcción de modelos de machine learning de alta calidad sin necesidad de una intervención manual significativa. H2OAutoML realiza automáticamente la selección de características, el ajuste de hiperparámetros, la validación cruzada y la combinación de modelos (stacking). Aquí tienes una explicación detallada de los parámetros disponibles en H2OAutoML:\n",
    "\n",
    "**Parámetros de `H2OAutoML`**\n",
    "\n",
    "1. **max_runtime_secs**:\n",
    "    * Descripción: Tiempo máximo en segundos que AutoML debe ejecutar.\n",
    "    * Ejemplo: max_runtime_secs=3600\n",
    "\n",
    "2. **max_models**:\n",
    "    * **Descripción**: Número máximo de modelos a entrenar.\n",
    "    * Ejemplo: max_models=50\n",
    "\n",
    "3. **stopping_metric**:\n",
    "    * Descripción: Métrica utilizada para detener el entrenamiento temprano.\n",
    "    * Valores: \"AUTO\", \"deviance\", \"logloss\", \"MSE\", \"RMSE\", \"MAE\", \"RMSLE\", \"AUC\", \"AUCPR\", \"lift_top_group\", \"misclassification\", \"mean_per_class_error\"\n",
    "    * Ejemplo: stopping_metric=\"RMSE\"\n",
    "\n",
    "4. **sort_metric**:\n",
    "    * Descripción: Métrica utilizada para ordenar los modelos en la tabla de líderes.\n",
    "    * Valores: \"AUTO\", \"deviance\", \"logloss\", \"MSE\", \"RMSE\", \"MAE\", \"RMSLE\", \"AUC\", \"AUCPR\", \"lift_top_group\", \"misclassification\", \"mean_per_class_error\"\n",
    "    * Ejemplo: sort_metric=\"RMSE\"\n",
    "\n",
    "5. **nfolds**:\n",
    "    * Descripción: Número de pliegues para la validación cruzada.\n",
    "    * Ejemplo: nfolds=5\n",
    "\n",
    "6. **keep_cross_validation_predictions**:\n",
    "    * Descripción: Booleano que indica si se deben mantener las predicciones de validación cruzada.\n",
    "    * Ejemplo: keep_cross_validation_predictions=True\n",
    "\n",
    "7. **keep_cross_validation_models**:\n",
    "    * Descripción: Booleano que indica si se deben mantener los modelos de validación cruzada.\n",
    "    * Ejemplo: keep_cross_validation_models=True\n",
    "\n",
    "8. **keep_cross_validation_fold_assignment**:\n",
    "    * Descripción: Booleano que indica si se deben mantener las asignaciones de pliegues de validación cruzada.\n",
    "    * Ejemplo: keep_cross_validation_fold_assignment=True\n",
    "\n",
    "9. **stopping_rounds**:\n",
    "    * Descripción: Número de rondas de parada temprana.\n",
    "    * Ejemplo: stopping_rounds=5\n",
    "\n",
    "10. **stopping_tolerance**:\n",
    "    * Descripción: Tolerancia para la métrica de parada temprana.\n",
    "    * Ejemplo: stopping_tolerance=1e-4\n",
    "\n",
    "11. **seed**:\n",
    "    * Descripción: Semilla para la generación de números aleatorios, lo que permite la reproducibilidad de los resultados.\n",
    "    * Ejemplo: seed=42\n",
    "\n",
    "12. **project_name**:\n",
    "    * Descripción: Nombre del proyecto para identificar los modelos generados.\n",
    "    * Ejemplo: project_name=\"COCOR_LEPANTO_aml_o3\"\n",
    "\n",
    "13. **exclude_algos**:\n",
    "    * Descripción: Lista de algoritmos a excluir del entrenamiento.\n",
    "    * Ejemplo: exclude_algos=[\"DeepLearning\", \"StackedEnsemble\"]\n",
    "\n",
    "14. **include_algos**:\n",
    "    * Descripción: Lista de algoritmos a incluir en el entrenamiento.\n",
    "    * Ejemplo: include_algos=[\"GLM\", \"GBM\"]\n",
    "\n",
    "15. **export_checkpoints_dir**:\n",
    "    * Descripción: directorio para exportar los puntos de control del modelo.\n",
    "    * Ejemplo: export_checkpoints_dir=\"/path/to/checkpoints\"\n",
    "\n",
    "16. **preprocessing**:\n",
    "    * Descripción: Lista de pasos de preprocesamiento a aplicar.\n",
    "    * Ejemplo: preprocessing=[\"target_encoding\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalized Linear Models (GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2OGeneralizedLinearEstimator` es una clase en H2O que se utiliza para construir modelos lineales generalizados (GLM). Los GLM son una extensión de los modelos lineales que permiten que la variable de respuesta tenga una distribución diferente a la normal. Esta clase es muy flexible y puede ser utilizada para una variedad de tareas de regresión y clasificación.\n",
    "\n",
    "**Parámetros de `H2OGeneralizedLinearEstimator`**\n",
    "\n",
    "1. **family**: Especifica la familia de la distribución de la variable de respuesta. Las opciones incluyen:\n",
    "   - `\"gaussian\"`: Para regresión lineal.\n",
    "   - `\"binomial\"`: Para clasificación binaria.\n",
    "   - `\"multinomial\"`: Para clasificación multiclase.\n",
    "   - `\"poisson\"`: Para regresión de conteo.\n",
    "   - `\"gamma\"`: Para regresión con distribución gamma.\n",
    "   - `\"tweedie\"`: Para modelos Tweedie.\n",
    "\n",
    "2. **link**: Especifica la función de enlace que relaciona la variable de respuesta con la combinación lineal de las variables predictoras. Las opciones dependen de la familia seleccionada.\n",
    "\n",
    "3. **alpha**: Parámetro de regularización que controla la mezcla entre L1 (Lasso) y L2 (Ridge). Un valor de 0 corresponde a Ridge, un valor de 1 corresponde a Lasso, y valores intermedios corresponden a una mezcla de ambos.\n",
    "\n",
    "4. **lambda**: Parámetro de regularización que controla la magnitud de la penalización. Un valor más alto implica una mayor penalización.\n",
    "\n",
    "5. **standardize**: Booleano que indica si las variables predictoras deben ser estandarizadas antes de ajustar el modelo. El valor predeterminado es `True`.\n",
    "\n",
    "6. **missing_values_handling**: Especifica cómo manejar los valores faltantes. Las opciones incluyen:\n",
    "   - `\"MeanImputation\"`: Imputación por la media.\n",
    "   - `\"Skip\"`: Omitir filas con valores faltantes.\n",
    "\n",
    "7. **nfolds**: Número de pliegues para la validación cruzada. El valor predeterminado es 0 (sin validación cruzada).\n",
    "\n",
    "8. **fold_assignment**: Método para asignar pliegues en la validación cruzada. Las opciones incluyen:\n",
    "   - `\"AUTO\"`\n",
    "   - `\"Random\"`\n",
    "   - `\"Modulo\"`\n",
    "   - `\"Stratified\"`\n",
    "\n",
    "9. **keep_cross_validation_predictions**: Booleano que indica si se deben mantener las predicciones de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "10. **intercept**: Booleano que indica si se debe incluir un término independiente en el modelo. El valor predeterminado es `True`.\n",
    "\n",
    "11. **max_iterations**: Número máximo de iteraciones para el algoritmo de optimización. El valor predeterminado es 50.\n",
    "\n",
    "12. **solver**: Especifica el algoritmo de optimización a utilizar. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"IRLSM\"`\n",
    "    - `\"L_BFGS\"`\n",
    "    - `\"COORDINATE_DESCENT\"`\n",
    "    - `\"COORDINATE_DESCENT_NAIVE\"`\n",
    "    - `\"GRADIENT_DESCENT_LH\"`\n",
    "    - `\"GRADIENT_DESCENT_SQERR\"`\n",
    "\n",
    "13. **beta_constraints**: DataFrame que especifica las restricciones en los coeficientes beta.\n",
    "\n",
    "14. **prior**: Probabilidad a priori para la clasificación binaria.\n",
    "\n",
    "15. **lambda_search**: Booleano que indica si se debe realizar una búsqueda de lambda. El valor predeterminado es `False`.\n",
    "\n",
    "16. **early_stopping**: Booleano que indica si se debe detener el entrenamiento temprano si no hay mejora en la métrica de validación. El valor predeterminado es `True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
      "Model Key: GLM_model_python_1737536124574_16\n",
      "\n",
      "\n",
      "GLM Model: summary\n",
      "    family    link      regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
      "--  --------  --------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  ------------------------------\n",
      "    gaussian  identity  Elastic Net (alpha = 0.5, lambda = 0.008857 )  17                            16                             1                       COCOR_LEPANTO_lagged_avg_train\n",
      "\n",
      "ModelMetricsRegressionGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 19.15287098695983\n",
      "RMSE: 4.376399317585157\n",
      "MAE: 3.4156566254921463\n",
      "RMSLE: 0.320669256701672\n",
      "Mean Residual Deviance: 19.15287098695983\n",
      "R^2: 0.596044800048676\n",
      "Null degrees of freedom: 643\n",
      "Residual degrees of freedom: 627\n",
      "Null deviance: 30534.200121915794\n",
      "Residual deviance: 12334.44891560213\n",
      "AIC: 3764.9723215121426\n",
      "\n",
      "Scoring History: \n",
      "    timestamp            duration    iterations    negative_log_likelihood    objective          training_rmse      training_deviance    training_mae        training_r2\n",
      "--  -------------------  ----------  ------------  -------------------------  -----------------  -----------------  -------------------  ------------------  -----------------\n",
      "    2025-01-23 11:37:17  0.000 sec   0             30534.200247324345         47.41335442131109\n",
      "    2025-01-23 11:37:17  0.014 sec   1                                                           4.376399317585157  19.15287098695983    3.4156566254921463  0.596044800048676\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "so2         2.87063                1                    0.212146\n",
      "o3          2.63932                0.919422             0.195051\n",
      "pm25        2.01833                0.703095             0.149159\n",
      "date        1.37278                0.478214             0.101451\n",
      "so2_lag_1   0.974845               0.339593             0.0720431\n",
      "pm10_lag_1  0.773729               0.269533             0.0571802\n",
      "so2_lag_3   0.599496               0.208838             0.044304\n",
      "so2_lag_2   0.419655               0.146189             0.0310134\n",
      "pm25_lag_3  0.390239               0.135942             0.0288395\n",
      "pm25_lag_1  0.358171               0.124771             0.0264696\n",
      "pm25_lag_2  0.340216               0.118516             0.0251427\n",
      "pm10        0.298446               0.103965             0.0220558\n",
      "o3_lag_1    0.173348               0.0603869            0.0128108\n",
      "pm10_lag_3  0.125384               0.0436781            0.00926611\n",
      "o3_lag_3    0.120156               0.0418569            0.00887976\n",
      "o3_lag_2    0.0566792              0.0197445            0.00418871\n",
      "pm10_lag_2  0                      0                    0\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "# G L M #\n",
    "#########\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "#guardamos el glm con un nombre especifico\n",
    "glm=H2OGeneralizedLinearEstimator()\n",
    "glm.train(x=x, y=y, training_frame=train_h2o)\n",
    "\n",
    "print(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.10704\n",
      " 0.151519\n",
      " 0.171365\n",
      " 0.233697\n",
      " 0.238545\n",
      " 0.246098\n",
      " 0.19248\n",
      " 0.240659\n",
      " 0.18887\n",
      " 0.139999\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = glm.predict(test_h2o)  \n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de y_true: 162\n",
      "Longitud de pred: 162\n",
      "RMSE: 0.14613210205746602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#pred = glm.predict(test_h2o)  \n",
    "\n",
    "# Obtenemos los valores reales de la variable objetivo\n",
    "y_true = test_df['no2']\n",
    "print(\"Longitud de y_true:\", len(y_true))\n",
    "\n",
    "\n",
    "# Convertir las predicciones a un DataFrame de pandas y asegurarse de que tenga la misma longitud que y_true\n",
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Machine (GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2OGradientBoostingEstimator` es una clase en H2O que se utiliza para construir modelos de boosting de gradiente. El boosting de gradiente es una técnica de machine learning que construye un modelo fuerte a partir de una serie de modelos débiles, generalmente árboles de decisión. Esta clase es muy flexible y puede ser utilizada para una variedad de tareas de regresión y clasificación.\n",
    "\n",
    "**Parámetros de `H2OGradientBoostingEstimator`**\n",
    "\n",
    "1. **ntrees**: Número de árboles a construir. El valor predeterminado es 50.\n",
    "\n",
    "2. **max_depth**: Profundidad máxima de cada árbol. Controla el grado de interacción entre las variables predictoras. El valor predeterminado es 5.\n",
    "\n",
    "3. **min_rows**: Número mínimo de observaciones en una hoja. El valor predeterminado es 10.\n",
    "\n",
    "4. **learn_rate**: Tasa de aprendizaje (también conocida como tasa de contracción). Controla la contribución de cada árbol. El valor predeterminado es 0.1.\n",
    "\n",
    "5. **sample_rate**: Proporción de filas a muestrear para cada árbol. El valor predeterminado es 1.0 (usar todas las filas).\n",
    "\n",
    "6. **col_sample_rate**: Proporción de columnas a muestrear para cada árbol. El valor predeterminado es 1.0 (usar todas las columnas).\n",
    "\n",
    "7. **col_sample_rate_per_tree**: Proporción de columnas a muestrear para cada árbol. El valor predeterminado es 1.0.\n",
    "\n",
    "8. **col_sample_rate_change_per_level**: Tasa de cambio de muestreo de columnas por nivel. El valor predeterminado es 1.0.\n",
    "\n",
    "9. **nbins**: Número de bins para dividir las variables continuas. El valor predeterminado es 20.\n",
    "\n",
    "10. **nbins_top_level**: Número de bins para dividir las variables continuas en el nivel superior. El valor predeterminado es 1024.\n",
    "\n",
    "11. **nbins_cats**: Número de bins para dividir las variables categóricas. El valor predeterminado es 1024.\n",
    "\n",
    "12. **stopping_rounds**: Número de rondas de parada temprana. Si no hay mejora en la métrica de validación durante estas rondas, el entrenamiento se detiene. El valor predeterminado es 0 (sin parada temprana).\n",
    "\n",
    "13. **stopping_metric**: Métrica utilizada para detener el entrenamiento temprano. Puede ser \"AUTO\", \"deviance\", \"logloss\", \"MSE\", \"RMSE\", \"MAE\", \"RMSLE\", \"AUC\", \"AUCPR\", \"lift_top_group\", \"misclassification\", \"mean_per_class_error\".\n",
    "\n",
    "14. **stopping_tolerance**: Tolerancia para la métrica de parada temprana. El valor predeterminado es 0.001.\n",
    "\n",
    "15. **score_each_iteration**: Booleano que indica si se debe puntuar el modelo en cada iteración. El valor predeterminado es `False`.\n",
    "\n",
    "16. **seed**: Semilla para la generación de números aleatorios, lo que permite la reproducibilidad de los resultados.\n",
    "\n",
    "17. **nfolds**: Número de pliegues para la validación cruzada. El valor predeterminado es 0 (sin validación cruzada).\n",
    "\n",
    "18. **fold_assignment**: Método para asignar pliegues en la validación cruzada. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Random\"`\n",
    "    - `\"Modulo\"`\n",
    "    - `\"Stratified\"`\n",
    "\n",
    "19. **keep_cross_validation_predictions**: Booleano que indica si se deben mantener las predicciones de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "20. **keep_cross_validation_models**: Booleano que indica si se deben mantener los modelos de validación cruzada. El valor predeterminado es `True`.\n",
    "\n",
    "21. **keep_cross_validation_fold_assignment**: Booleano que indica si se deben mantener las asignaciones de pliegues de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "22. **distribution**: Distribución de la variable de respuesta. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"bernoulli\"`\n",
    "    - `\"multinomial\"`\n",
    "    - `\"gaussian\"`\n",
    "    - `\"poisson\"`\n",
    "    - `\"gamma\"`\n",
    "    - `\"tweedie\"`\n",
    "    - `\"laplace\"`\n",
    "    - `\"quantile\"`\n",
    "    - `\"huber\"`\n",
    "\n",
    "23. **categorical_encoding**: Método de codificación para variables categóricas. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Enum\"`\n",
    "    - `\"OneHotInternal\"`\n",
    "    - `\"OneHotExplicit\"`\n",
    "    - `\"Binary\"`\n",
    "    - `\"Eigen\"`\n",
    "    - `\"LabelEncoder\"`\n",
    "    - `\"SortByResponse\"`\n",
    "    - `\"EnumLimited\"`\n",
    "\n",
    "24. **max_abs_leafnode_pred**: Predicción máxima absoluta de la hoja. El valor predeterminado es `None`.\n",
    "\n",
    "25. **pred_noise_bandwidth**: Ancho de banda del ruido de predicción. El valor predeterminado es 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator : Gradient Boosting Machine\n",
      "Model Key: GBM_model_python_1737536124574_4\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
      "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
      "    50                 50                          15201                  5            5            5             7             27            19.5\n",
      "\n",
      "ModelMetricsRegression: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0032925817558564522\n",
      "RMSE: 0.05738102261075914\n",
      "MAE: 0.044332673920925686\n",
      "RMSLE: 0.04221733021727318\n",
      "Mean Residual Deviance: 0.0032925817558564522\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse         training_mae          training_deviance\n",
      "---  -------------------  ----------  -----------------  --------------------  --------------------  ---------------------\n",
      "     2025-01-22 13:41:40  0.021 sec   0.0                0.19409581252709893   0.16070887055173294   0.03767318444055473\n",
      "     2025-01-22 13:41:40  0.208 sec   1.0                0.18059425387222186   0.149171836457539     0.032614284531664525\n",
      "     2025-01-22 13:41:40  0.279 sec   2.0                0.1687685486270616    0.1390612822011146    0.028482823005684856\n",
      "     2025-01-22 13:41:40  0.332 sec   3.0                0.15842591865259323   0.13007887167395046   0.025098771700918086\n",
      "     2025-01-22 13:41:40  0.366 sec   4.0                0.14914171228926124   0.12214326693394684   0.022243250344572776\n",
      "     2025-01-22 13:41:40  0.396 sec   5.0                0.14077239950841053   0.11483475953793447   0.019816868463355543\n",
      "     2025-01-22 13:41:40  0.419 sec   6.0                0.13354398924398148   0.10864858775025343   0.01783399706319664\n",
      "     2025-01-22 13:41:40  0.462 sec   7.0                0.12748984784053682   0.10369430849446047   0.01625366130240323\n",
      "     2025-01-22 13:41:40  0.480 sec   8.0                0.12182631383251313   0.09933425670352555   0.014841650742017981\n",
      "     2025-01-22 13:41:40  0.499 sec   9.0                0.11614322424567644   0.09457550599605914   0.013489248538181483\n",
      "---  ---                  ---         ---                ---                   ---                   ---\n",
      "     2025-01-22 13:41:41  1.037 sec   41.0               0.06154773522496216   0.04771376521820011   0.003788123711322048\n",
      "     2025-01-22 13:41:41  1.047 sec   42.0               0.0611161217133749    0.04737510725082406   0.0037351803332840556\n",
      "     2025-01-22 13:41:41  1.057 sec   43.0               0.06016749984965822   0.046629604574263794  0.0036201280381586215\n",
      "     2025-01-22 13:41:41  1.065 sec   44.0               0.059906778625356136  0.046449569739673034  0.0035888221252674264\n",
      "     2025-01-22 13:41:41  1.074 sec   45.0               0.05940062845410485   0.04601339462255428   0.003528434660742611\n",
      "     2025-01-22 13:41:41  1.081 sec   46.0               0.05871135567278028   0.04548898271327207   0.003447023284935709\n",
      "     2025-01-22 13:41:41  1.094 sec   47.0               0.0584346482919982    0.04524157132966692   0.0034146081210095288\n",
      "     2025-01-22 13:41:41  1.102 sec   48.0               0.05809708785140441   0.044925272658785265  0.0033752716168138023\n",
      "     2025-01-22 13:41:41  1.109 sec   49.0               0.05769658319882301   0.04458515109195246   0.0033288957128187057\n",
      "     2025-01-22 13:41:41  1.120 sec   50.0               0.05738102261075914   0.044332673920925686  0.0032925817558564522\n",
      "[51 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "o3          57.688                 1                    0.495019\n",
      "pm25        16.1628                0.280176             0.138692\n",
      "date        7.77446                0.134767             0.0667125\n",
      "so2         6.86305                0.118968             0.0588917\n",
      "pm10        4.60049                0.0797477            0.0394767\n",
      "pm25_lag_1  3.72839                0.0646303            0.0319933\n",
      "o3_lag_3    2.56392                0.0444447            0.022001\n",
      "so2_lag_3   2.47107                0.0428351            0.0212042\n",
      "pm25_lag_2  2.33803                0.0405289            0.0200626\n",
      "so2_lag_2   2.01798                0.0349809            0.0173162\n",
      "o3_lag_2    1.90921                0.0330954            0.0163829\n",
      "pm10_lag_3  1.85446                0.0321465            0.0159131\n",
      "pm10_lag_1  1.44401                0.0250313            0.012391\n",
      "pm25_lag_3  1.42594                0.0247181            0.0122359\n",
      "pm10_lag_2  1.38666                0.0240373            0.0118989\n",
      "o3_lag_1    1.3565                 0.0235144            0.0116401\n",
      "so2_lag_1   0.951892               0.0165007            0.00816816\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "gmb = H2OGradientBoostingEstimator()\n",
    "gmb.train(x=x, y=y, training_frame=train_h2o)\n",
    "print(gmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.131784\n",
      " 0.150984\n",
      " 0.207563\n",
      " 0.23713\n",
      " 0.293336\n",
      " 0.240244\n",
      " 0.233961\n",
      " 0.213364\n",
      " 0.194998\n",
      " 0.169494\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = gmb.predict(test_h2o)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de y_true: 162\n",
      "Longitud de pred: 162\n",
      "RMSE: 0.12955100220182264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los valores reales de la variable objetivo\n",
    "y_true = test_df['no2']\n",
    "print(\"Longitud de y_true:\", len(y_true))\n",
    "\n",
    "# Convertir las predicciones a un DataFrame de pandas y asegurarse de que tenga la misma longitud que y_true\n",
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2ORandomForestEstimator` es una clase en H2O que se utiliza para construir modelos de bosque aleatorio (Random Forest). Un bosque aleatorio es un conjunto de árboles de decisión entrenados en diferentes subconjuntos del conjunto de datos, y sus predicciones se combinan para mejorar la precisión y controlar el sobreajuste.\n",
    "\n",
    "**Parámetros de `H2ORandomForestEstimator`**\n",
    "\n",
    "1. **ntrees**: Número de árboles a construir. El valor predeterminado es 50.\n",
    "\n",
    "2. **max_depth**: Profundidad máxima de cada árbol. Controla el grado de interacción entre las variables predictoras. El valor predeterminado es 20.\n",
    "\n",
    "3. **min_rows**: Número mínimo de observaciones en una hoja. El valor predeterminado es 1.\n",
    "\n",
    "4. **nbins**: Número de bins para dividir las variables continuas. El valor predeterminado es 20.\n",
    "\n",
    "5. **nbins_top_level**: Número de bins para dividir las variables continuas en el nivel superior. El valor predeterminado es 1024.\n",
    "\n",
    "6. **nbins_cats**: Número de bins para dividir las variables categóricas. El valor predeterminado es 1024.\n",
    "\n",
    "7. **mtries**: Número de variables a muestrear aleatoriamente como candidatas en cada división. El valor predeterminado es -1 (sqrt(p) para clasificación y p/3 para regresión, donde p es el número de predictores).\n",
    "\n",
    "8. **sample_rate**: Proporción de filas a muestrear para cada árbol. El valor predeterminado es 0.632 (muestreo con reemplazo).\n",
    "\n",
    "9. **col_sample_rate_per_tree**: Proporción de columnas a muestrear para cada árbol. El valor predeterminado es 1.0.\n",
    "\n",
    "10. **col_sample_rate_change_per_level**: Tasa de cambio de muestreo de columnas por nivel. El valor predeterminado es 1.0.\n",
    "\n",
    "11. **stopping_rounds**: Número de rondas de parada temprana. Si no hay mejora en la métrica de validación durante estas rondas, el entrenamiento se detiene. El valor predeterminado es 0 (sin parada temprana).\n",
    "\n",
    "12. **stopping_metric**: Métrica utilizada para detener el entrenamiento temprano. Puede ser \"AUTO\", \"deviance\", \"logloss\", \"MSE\", \"RMSE\", \"MAE\", \"RMSLE\", \"AUC\", \"AUCPR\", \"lift_top_group\", \"misclassification\", \"mean_per_class_error\".\n",
    "\n",
    "13. **stopping_tolerance**: Tolerancia para la métrica de parada temprana. El valor predeterminado es 0.001.\n",
    "\n",
    "14. **score_each_iteration**: Booleano que indica si se debe puntuar el modelo en cada iteración. El valor predeterminado es `False`.\n",
    "\n",
    "15. **seed**: Semilla para la generación de números aleatorios, lo que permite la reproducibilidad de los resultados.\n",
    "\n",
    "16. **nfolds**: Número de pliegues para la validación cruzada. El valor predeterminado es 0 (sin validación cruzada).\n",
    "\n",
    "17. **fold_assignment**: Método para asignar pliegues en la validación cruzada. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Random\"`\n",
    "    - `\"Modulo\"`\n",
    "    - `\"Stratified\"`\n",
    "\n",
    "18. **keep_cross_validation_predictions**: Booleano que indica si se deben mantener las predicciones de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "19. **keep_cross_validation_models**: Booleano que indica si se deben mantener los modelos de validación cruzada. El valor predeterminado es `True`.\n",
    "\n",
    "20. **keep_cross_validation_fold_assignment**: Booleano que indica si se deben mantener las asignaciones de pliegues de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "21. **distribution**: Distribución de la variable de respuesta. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"bernoulli\"`\n",
    "    - `\"multinomial\"`\n",
    "    - `\"gaussian\"`\n",
    "    - `\"poisson\"`\n",
    "    - `\"gamma\"`\n",
    "    - `\"tweedie\"`\n",
    "    - `\"laplace\"`\n",
    "    - `\"quantile\"`\n",
    "    - `\"huber\"`\n",
    "\n",
    "22. **categorical_encoding**: Método de codificación para variables categóricas. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Enum\"`\n",
    "    - `\"OneHotInternal\"`\n",
    "    - `\"OneHotExplicit\"`\n",
    "    - `\"Binary\"`\n",
    "    - `\"Eigen\"`\n",
    "    - `\"LabelEncoder\"`\n",
    "    - `\"SortByResponse\"`\n",
    "    - `\"EnumLimited\"`\n",
    "\n",
    "23. **max_abs_leafnode_pred**: Predicción máxima absoluta de la hoja. El valor predeterminado es `None`.\n",
    "\n",
    "24. **pred_noise_bandwidth**: Ancho de banda del ruido de predicción. El valor predeterminado es 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ORandomForestEstimator : Distributed Random Forest\n",
      "Model Key: DRF_model_python_1737536124574_5\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
      "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
      "    50                 50                          256501                 16           20           18.88         378           427           403.66\n",
      "\n",
      "ModelMetricsRegression: drf\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.014400583323284078\n",
      "RMSE: 0.12000243048907\n",
      "MAE: 0.09632706742686495\n",
      "RMSLE: 0.08814939117795374\n",
      "Mean Residual Deviance: 0.014400583323284078\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse        training_mae         training_deviance\n",
      "---  -------------------  ----------  -----------------  -------------------  -------------------  --------------------\n",
      "     2025-01-22 13:44:12  0.005 sec   0.0                nan                  nan                  nan\n",
      "     2025-01-22 13:44:13  0.109 sec   1.0                0.1621182683116245   0.129428224053508    0.026282332920359874\n",
      "     2025-01-22 13:44:13  0.172 sec   2.0                0.16532564087770776  0.13129870335204882  0.0273325675316248\n",
      "     2025-01-22 13:44:13  0.219 sec   3.0                0.16505194539503498  0.12885188124641003  0.027242144678685607\n",
      "     2025-01-22 13:44:13  0.264 sec   4.0                0.1592590264717094   0.12436322016959422  0.02536343751271663\n",
      "     2025-01-22 13:44:13  0.324 sec   5.0                0.1520205830297832   0.11921276195010674  0.023110257664715205\n",
      "     2025-01-22 13:44:13  0.370 sec   6.0                0.14936390641980984  0.1164440517327782   0.02230957654098571\n",
      "     2025-01-22 13:44:13  0.417 sec   7.0                0.14828441639932388  0.11617728074489506  0.02198826814688807\n",
      "     2025-01-22 13:44:13  0.464 sec   8.0                0.1419888467773246   0.11244818846315824  0.02016083260915456\n",
      "     2025-01-22 13:44:13  0.514 sec   9.0                0.14049187381284234  0.11204992939072392  0.019737966607443615\n",
      "---  ---                  ---         ---                ---                  ---                  ---\n",
      "     2025-01-22 13:44:14  1.684 sec   41.0               0.12110836770489587  0.09729439778116077  0.014667236728144266\n",
      "     2025-01-22 13:44:14  1.708 sec   42.0               0.12087782347188307  0.09705973230981571  0.014611448207299727\n",
      "     2025-01-22 13:44:14  1.735 sec   43.0               0.1206942377933755   0.09690136848991421  0.014567099036523872\n",
      "     2025-01-22 13:44:14  1.764 sec   44.0               0.1207093505862351   0.09693541799246158  0.014570747318950616\n",
      "     2025-01-22 13:44:14  1.792 sec   45.0               0.1204937921915586   0.09676423463298633  0.014518753956702508\n",
      "     2025-01-22 13:44:14  1.815 sec   46.0               0.1207215939969858   0.09705566749919048  0.014573703257173078\n",
      "     2025-01-22 13:44:14  1.842 sec   47.0               0.12074638373024495  0.09693730406133151  0.014579689183931563\n",
      "     2025-01-22 13:44:14  1.872 sec   48.0               0.12055992837405427  0.09692946677975942  0.014534696329557095\n",
      "     2025-01-22 13:44:14  1.901 sec   49.0               0.12043641731298883  0.09665577568694422  0.014504930615188398\n",
      "     2025-01-22 13:44:14  1.946 sec   50.0               0.12000243048907     0.09632706742686495  0.014400583323284078\n",
      "[51 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "o3          167.479                1                    0.186561\n",
      "o3_lag_1    158.901                0.948778             0.177005\n",
      "o3_lag_2    92.4623                0.552082             0.102997\n",
      "pm25        87.3659                0.521652             0.0973198\n",
      "o3_lag_3    83.4578                0.498317             0.0929664\n",
      "so2         61.684                 0.368308             0.0687118\n",
      "pm10        47.4597                0.283377             0.052867\n",
      "pm25_lag_1  31.3455                0.187161             0.0349168\n",
      "so2_lag_1   24.9875                0.149197             0.0278343\n",
      "date        21.8851                0.130673             0.0243785\n",
      "pm10_lag_1  19.5471                0.116714             0.0217742\n",
      "pm25_lag_2  18.2886                0.109199             0.0203723\n",
      "so2_lag_2   17.95                  0.107178             0.0199951\n",
      "so2_lag_3   16.8161                0.100407             0.018732\n",
      "pm25_lag_3  16.5922                0.0990703            0.0184826\n",
      "pm10_lag_3  16.4556                0.0982543            0.0183304\n",
      "pm10_lag_2  15.0426                0.0898176            0.0167564\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "rf=H2ORandomForestEstimator()\n",
    "rf.train(x=x, y=y, training_frame=train_h2o)\n",
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.17475\n",
      " 0.18487\n",
      " 0.222632\n",
      " 0.228026\n",
      " 0.236126\n",
      " 0.256347\n",
      " 0.236346\n",
      " 0.206166\n",
      " 0.203674\n",
      " 0.165084\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=rf.predict(test_h2o)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de pred: 162\n",
      "RMSE: 0.1181724690402531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning (Redes Neuronales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2ODeepLearningEstimator` es una clase en H2O que se utiliza para construir modelos de redes neuronales profundas (Deep Learning). Este tipo de modelo es una red neuronal artificial con múltiples capas ocultas entre la capa de entrada y la capa de salida. Las redes neuronales profundas son capaces de capturar patrones complejos en los datos y son adecuadas para una variedad de tareas de regresión y clasificación.\n",
    "\n",
    "**Parámetros de `H2ODeepLearningEstimator`**\n",
    "\n",
    "1. **hidden**: Lista que especifica el número de unidades en cada capa oculta. Por ejemplo, `[200, 200]` crea una red con dos capas ocultas, cada una con 200 unidades.\n",
    "\n",
    "2. **epochs**: Número de épocas para entrenar el modelo. Una época es una pasada completa por el conjunto de datos de entrenamiento. El valor predeterminado es 10.\n",
    "\n",
    "3. **activation**: Función de activación para las unidades ocultas. Las opciones incluyen:\n",
    "   - `\"Tanh\"`\n",
    "   - `\"TanhWithDropout\"`\n",
    "   - `\"Rectifier\"`\n",
    "   - `\"RectifierWithDropout\"`\n",
    "   - `\"Maxout\"`\n",
    "   - `\"MaxoutWithDropout\"`\n",
    "\n",
    "4. **input_dropout_ratio**: Proporción de unidades de entrada que se deben omitir (dropout) durante el entrenamiento. El valor predeterminado es 0.0.\n",
    "\n",
    "5. **hidden_dropout_ratios**: Lista que especifica la proporción de unidades ocultas que se deben omitir (dropout) en cada capa oculta. Debe tener la misma longitud que el parámetro `hidden`.\n",
    "\n",
    "6. **l1**: Parámetro de regularización L1. El valor predeterminado es 0.0.\n",
    "\n",
    "7. **l2**: Parámetro de regularización L2. El valor predeterminado es 0.0.\n",
    "\n",
    "8. **rho**: Parámetro de decaimiento para la media móvil de los gradientes cuadrados (utilizado en AdaDelta). El valor predeterminado es 0.99.\n",
    "\n",
    "9. **epsilon**: Parámetro de estabilización para la media móvil de los gradientes cuadrados (utilizado en AdaDelta). El valor predeterminado es 1e-8.\n",
    "\n",
    "10. **rate**: Tasa de aprendizaje inicial. El valor predeterminado es 0.005.\n",
    "\n",
    "11. **rate_annealing**: Tasa de disminución de la tasa de aprendizaje. El valor predeterminado es 1e-6.\n",
    "\n",
    "12. **rate_decay**: Factor de decaimiento de la tasa de aprendizaje. El valor predeterminado es 1.0.\n",
    "\n",
    "13. **momentum_start**: Momento inicial en el entrenamiento. El valor predeterminado es 0.0.\n",
    "\n",
    "14. **momentum_ramp**: Número de épocas sobre las cuales aumentar el momento inicial hasta el valor de `momentum_stable`. El valor predeterminado es 1e6.\n",
    "\n",
    "15. **momentum_stable**: Momento estable después del aumento inicial. El valor predeterminado es 0.0.\n",
    "\n",
    "16. **nesterov_accelerated_gradient**: Booleano que indica si se debe utilizar el gradiente acelerado de Nesterov. El valor predeterminado es `True`.\n",
    "\n",
    "17. **max_w2**: Valor máximo para los pesos. El valor predeterminado es `Inf`.\n",
    "\n",
    "18. **initial_weight_distribution**: Distribución inicial de los pesos. Las opciones incluyen:\n",
    "    - `\"UniformAdaptive\"`\n",
    "    - `\"Uniform\"`\n",
    "    - `\"Normal\"`\n",
    "\n",
    "19. **initial_weight_scale**: Escala para la distribución inicial de los pesos. El valor predeterminado es 1.0.\n",
    "\n",
    "20. **loss**: Función de pérdida a optimizar. Las opciones incluyen:\n",
    "    - `\"Automatic\"`\n",
    "    - `\"CrossEntropy\"`\n",
    "    - `\"Quadratic\"`\n",
    "    - `\"Huber\"`\n",
    "    - `\"Absolute\"`\n",
    "\n",
    "21. **distribution**: Distribución de la variable de respuesta. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"bernoulli\"`\n",
    "    - `\"multinomial\"`\n",
    "    - `\"gaussian\"`\n",
    "    - `\"poisson\"`\n",
    "    - `\"gamma\"`\n",
    "    - `\"tweedie\"`\n",
    "    - `\"laplace\"`\n",
    "    - `\"quantile\"`\n",
    "    - `\"huber\"`\n",
    "\n",
    "22. **nfolds**: Número de pliegues para la validación cruzada. El valor predeterminado es 0 (sin validación cruzada).\n",
    "\n",
    "23. **fold_assignment**: Método para asignar pliegues en la validación cruzada. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Random\"`\n",
    "    - `\"Modulo\"`\n",
    "    - `\"Stratified\"`\n",
    "\n",
    "24. **keep_cross_validation_predictions**: Booleano que indica si se deben mantener las predicciones de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "25. **keep_cross_validation_models**: Booleano que indica si se deben mantener los modelos de validación cruzada. El valor predeterminado es `True`.\n",
    "\n",
    "26. **keep_cross_validation_fold_assignment**: Booleano que indica si se deben mantener las asignaciones de pliegues de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "27. **seed**: Semilla para la generación de números aleatorios, lo que permite la reproducibilidad de los resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator : Deep Learning\n",
      "Model Key: DeepLearning_model_python_1737536124574_6\n",
      "\n",
      "\n",
      "Status of Neuron Layers: predicting no2, regression, gaussian distribution, Quadratic loss, 301 weights/biases, 9,0 KB, 6.440 training samples, mini-batch size 1\n",
      "    layer    units    type       dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms          mean_bias             bias_rms\n",
      "--  -------  -------  ---------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  ------------------  --------------------  -----------------------\n",
      "    1        17       Input      0.0\n",
      "    2        10       Rectifier  0.0        0.0   0.0   0.001665120112011209   0.0008475033100694418  0.0         -0.015323673240730867  0.2584160566329956  0.4536642916041126    0.052220284938812256\n",
      "    3        10       Rectifier  0.0        0.0   0.0   0.007304709926538635   0.014361146837472916   0.0         -0.002816972988657653  0.288907527923584   0.9934535525378706    0.06610357761383057\n",
      "    4        1        Linear                0.0   0.0   0.0009345332116936333  0.0008342394139617682  0.0         0.11158354869112372    0.4119911193847656  0.042607815767604175  1.0971281125650402e-154\n",
      "\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.013411366224549264\n",
      "RMSE: 0.11580745323401799\n",
      "MAE: 0.09319807384890437\n",
      "RMSLE: 0.08597191243563879\n",
      "Mean Residual Deviance: 0.013411366224549264\n",
      "\n",
      "Scoring History: \n",
      "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_deviance    training_mae    training_r2\n",
      "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  -------------------  --------------  -------------\n",
      "    2025-01-22 13:46:21  0.000 sec                     0         0             0          nan              nan                  nan             nan\n",
      "    2025-01-22 13:46:21  0.184 sec   11925 obs/sec     1         1             644        0.15219          0.0231617            0.119201        0.385194\n",
      "    2025-01-22 13:46:21  0.380 sec   26945 obs/sec     10        10            6440       0.115807         0.0134114            0.0931981       0.644008\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "pm25_lag_1  1                      1                    0.0704475\n",
      "pm25_lag_3  0.998686               0.998686             0.070355\n",
      "pm10        0.993145               0.993145             0.0699646\n",
      "o3          0.967731               0.967731             0.0681743\n",
      "o3_lag_1    0.923331               0.923331             0.0650464\n",
      "so2_lag_1   0.895874               0.895874             0.0631121\n",
      "pm10_lag_1  0.846102               0.846102             0.0596058\n",
      "pm10_lag_3  0.845036               0.845036             0.0595307\n",
      "pm25        0.840873               0.840873             0.0592374\n",
      "pm25_lag_2  0.803087               0.803087             0.0565755\n",
      "o3_lag_2    0.788143               0.788143             0.0555227\n",
      "so2_lag_2   0.767149               0.767149             0.0540438\n",
      "o3_lag_3    0.754443               0.754443             0.0531487\n",
      "so2_lag_3   0.73518                0.73518              0.0517916\n",
      "date        0.708475               0.708475             0.0499103\n",
      "so2         0.669906               0.669906             0.0471932\n",
      "pm10_lag_2  0.6578                 0.6578               0.0463404\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2ODeepLearningEstimator\n",
    "dl=H2ODeepLearningEstimator(hidden=[10,10], epochs=10)\n",
    "dl.train(x=x, y=y, training_frame=train_h2o)\n",
    "print(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.189332\n",
      " 0.17382\n",
      " 0.189645\n",
      " 0.22293\n",
      " 0.235436\n",
      " 0.265645\n",
      " 0.239835\n",
      " 0.288483\n",
      " 0.216216\n",
      " 0.212283\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=dl.predict(test_h2o)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de pred: 162\n",
      "RMSE: 0.15358691666259042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost (Extreme Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2OXGBoostEstimator` es una clase en H2O que se utiliza para construir modelos de XGBoost. XGBoost (Extreme Gradient Boosting) es una implementación optimizada de boosting de gradiente que ha demostrado ser muy eficaz en una variedad de tareas de machine learning, especialmente en competiciones de Kaggle.\n",
    "\n",
    "**Parámetros de `H2OXGBoostEstimator`**\n",
    "\n",
    "1. **ntrees**: Número de árboles a construir. El valor predeterminado es 50.\n",
    "\n",
    "2. **max_depth**: Profundidad máxima de cada árbol. Controla el grado de interacción entre las variables predictoras. El valor predeterminado es 6.\n",
    "\n",
    "3. **min_rows**: Número mínimo de observaciones en una hoja. El valor predeterminado es 1.\n",
    "\n",
    "4. **learn_rate**: Tasa de aprendizaje (también conocida como tasa de contracción). Controla la contribución de cada árbol. El valor predeterminado es 0.3.\n",
    "\n",
    "5. **sample_rate**: Proporción de filas a muestrear para cada árbol. El valor predeterminado es 1.0 (usar todas las filas).\n",
    "\n",
    "6. **col_sample_rate**: Proporción de columnas a muestrear para cada árbol. El valor predeterminado es 1.0 (usar todas las columnas).\n",
    "\n",
    "7. **col_sample_rate_per_tree**: Proporción de columnas a muestrear para cada árbol. El valor predeterminado es 1.0.\n",
    "\n",
    "8. **col_sample_rate_change_per_level**: Tasa de cambio de muestreo de columnas por nivel. El valor predeterminado es 1.0.\n",
    "\n",
    "9. **nbins**: Número de bins para dividir las variables continuas. El valor predeterminado es 256.\n",
    "\n",
    "10. **nbins_top_level**: Número de bins para dividir las variables continuas en el nivel superior. El valor predeterminado es 1024.\n",
    "\n",
    "11. **nbins_cats**: Número de bins para dividir las variables categóricas. El valor predeterminado es 1024.\n",
    "\n",
    "12. **stopping_rounds**: Número de rondas de parada temprana. Si no hay mejora en la métrica de validación durante estas rondas, el entrenamiento se detiene. El valor predeterminado es 0 (sin parada temprana).\n",
    "\n",
    "13. **stopping_metric**: Métrica utilizada para detener el entrenamiento temprano. Puede ser \"AUTO\", \"deviance\", \"logloss\", \"MSE\", \"RMSE\", \"MAE\", \"RMSLE\", \"AUC\", \"AUCPR\", \"lift_top_group\", \"misclassification\", \"mean_per_class_error\".\n",
    "\n",
    "14. **stopping_tolerance**: Tolerancia para la métrica de parada temprana. El valor predeterminado es 0.001.\n",
    "\n",
    "15. **score_each_iteration**: Booleano que indica si se debe puntuar el modelo en cada iteración. El valor predeterminado es `False`.\n",
    "\n",
    "16. **seed**: Semilla para la generación de números aleatorios, lo que permite la reproducibilidad de los resultados.\n",
    "\n",
    "17. **nfolds**: Número de pliegues para la validación cruzada. El valor predeterminado es 0 (sin validación cruzada).\n",
    "\n",
    "18. **fold_assignment**: Método para asignar pliegues en la validación cruzada. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Random\"`\n",
    "    - `\"Modulo\"`\n",
    "    - `\"Stratified\"`\n",
    "\n",
    "19. **keep_cross_validation_predictions**: Booleano que indica si se deben mantener las predicciones de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "20. **keep_cross_validation_models**: Booleano que indica si se deben mantener los modelos de validación cruzada. El valor predeterminado es `True`.\n",
    "\n",
    "21. **keep_cross_validation_fold_assignment**: Booleano que indica si se deben mantener las asignaciones de pliegues de validación cruzada. El valor predeterminado es `False`.\n",
    "\n",
    "22. **booster**: Tipo de booster a utilizar. Las opciones incluyen:\n",
    "    - `\"gbtree\"`: Árboles de decisión.\n",
    "    - `\"gblinear\"`: Modelos lineales.\n",
    "    - `\"dart\"`: Árboles de decisión con dropout.\n",
    "\n",
    "23. **tree_method**: Método de construcción de árboles. Las opciones incluyen:\n",
    "    - `\"auto\"`\n",
    "    - `\"exact\"`\n",
    "    - `\"approx\"`\n",
    "    - `\"hist\"`\n",
    "    - `\"gpu_hist\"`\n",
    "\n",
    "24. **grow_policy**: Política de crecimiento de los árboles. Las opciones incluyen:\n",
    "    - `\"depthwise\"`\n",
    "    - `\"lossguide\"`\n",
    "\n",
    "25. **max_bins**: Número máximo de bins para discretizar las características continuas. El valor predeterminado es 256.\n",
    "\n",
    "26. **reg_lambda**: Parámetro de regularización L2. El valor predeterminado es 1.0.\n",
    "\n",
    "27. **reg_alpha**: Parámetro de regularización L1. El valor predeterminado es 0.0.\n",
    "\n",
    "28. **scale_pos_weight**: Peso de las clases positivas en la clasificación binaria. El valor predeterminado es 1.0.\n",
    "\n",
    "29. **distribution**: Distribución de la variable de respuesta. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"bernoulli\"`\n",
    "    - `\"multinomial\"`\n",
    "    - `\"gaussian\"`\n",
    "    - `\"poisson\"`\n",
    "    - `\"gamma\"`\n",
    "    - `\"tweedie\"`\n",
    "    - `\"laplace\"`\n",
    "    - `\"quantile\"`\n",
    "    - `\"huber\"`\n",
    "\n",
    "30. **categorical_encoding**: Método de codificación para variables categóricas. Las opciones incluyen:\n",
    "    - `\"AUTO\"`\n",
    "    - `\"Enum\"`\n",
    "    - `\"OneHotInternal\"`\n",
    "    - `\"OneHotExplicit\"`\n",
    "    - `\"Binary\"`\n",
    "    - `\"Eigen\"`\n",
    "    - `\"LabelEncoder\"`\n",
    "    - `\"SortByResponse\"`\n",
    "    - `\"EnumLimited\"`\n",
    "\n",
    "31. **max_abs_leafnode_pred**: Predicción máxima absoluta de la hoja. El valor predeterminado es `None`.\n",
    "\n",
    "32. **pred_noise_bandwidth**: Ancho de banda del ruido de predicción. El valor predeterminado es 0.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost Model Build progress: |██████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator : XGBoost\n",
      "Model Key: XGBoost_model_python_1737536124574_7\n",
      "\n",
      "\n",
      "Model Summary: \n",
      "    number_of_trees\n",
      "--  -----------------\n",
      "    50\n",
      "\n",
      "ModelMetricsRegression: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 5.589453530351202e-05\n",
      "RMSE: 0.007476264796240969\n",
      "MAE: 0.005225304899094966\n",
      "RMSLE: 0.005669719607208128\n",
      "Mean Residual Deviance: 5.589453530351202e-05\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    number_of_trees    training_rmse         training_mae          training_deviance\n",
      "---  -------------------  ----------  -----------------  --------------------  --------------------  ----------------------\n",
      "     2025-01-22 13:48:15  0.020 sec   0.0                0.2515649299471462    0.21498761480259374   0.06328491397931256\n",
      "     2025-01-22 13:48:15  0.382 sec   1.0                0.1902076367736171    0.16114423411593448   0.036178945087004255\n",
      "     2025-01-22 13:48:15  0.453 sec   2.0                0.1476387028607193    0.12360012398548521   0.021797186582395767\n",
      "     2025-01-22 13:48:15  0.522 sec   3.0                0.11782595004405498   0.09749600635172191   0.01388295450378414\n",
      "     2025-01-22 13:48:16  0.716 sec   4.0                0.09712775186891648   0.07929866868877036   0.00943380018310981\n",
      "     2025-01-22 13:48:16  0.899 sec   5.0                0.08080314407536224   0.06540606121459136   0.006529148092463747\n",
      "     2025-01-22 13:48:16  1.104 sec   6.0                0.06882995037916316   0.05503870913876283   0.004737562069198064\n",
      "     2025-01-22 13:48:16  1.213 sec   7.0                0.06119407217615564   0.048355135340954904  0.003744714469500546\n",
      "     2025-01-22 13:48:16  1.424 sec   8.0                0.05542146594392566   0.04333580887224507   0.0030715388873737122\n",
      "     2025-01-22 13:48:16  1.560 sec   9.0                0.049819975467433684  0.03853600722421174   0.002482029955575694\n",
      "---  ---                  ---         ---                ---                   ---                   ---\n",
      "     2025-01-22 13:48:18  2.807 sec   41.0               0.011620225276593633  0.0083650963105757    0.00013502963547878558\n",
      "     2025-01-22 13:48:18  2.835 sec   42.0               0.01107081303700176   0.007987541155501881  0.00012256290130024814\n",
      "     2025-01-22 13:48:18  2.864 sec   43.0               0.010500101987991325  0.007518754384341405  0.00011025214175821938\n",
      "     2025-01-22 13:48:18  2.894 sec   44.0               0.009821808281971142  0.006940658703428854  9.646791792779693e-05\n",
      "     2025-01-22 13:48:18  2.924 sec   45.0               0.009561934928157753  0.006706841874491497  9.143059957032322e-05\n",
      "     2025-01-22 13:48:18  2.953 sec   46.0               0.008862090852891007  0.006258567402052356  7.853665428489447e-05\n",
      "     2025-01-22 13:48:18  2.982 sec   47.0               0.008602934215648905  0.006039234815610635  7.401047711878262e-05\n",
      "     2025-01-22 13:48:18  3.010 sec   48.0               0.008210968622792759  0.005778202827782507  6.742000572448721e-05\n",
      "     2025-01-22 13:48:18  3.035 sec   49.0               0.007761818899684436  0.005449457914290642  6.02458326314985e-05\n",
      "     2025-01-22 13:48:18  3.063 sec   50.0               0.007476264796240969  0.005225304899094966  5.589453530351202e-05\n",
      "[51 rows x 7 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "o3          21.7292                1                    0.472867\n",
      "pm25        6.82127                0.313921             0.148443\n",
      "date        3.4853                 0.160397             0.0758463\n",
      "so2         2.48445                0.114337             0.054066\n",
      "pm10        1.66727                0.0767292            0.0362827\n",
      "o3_lag_3    1.31099                0.0603332            0.0285296\n",
      "pm25_lag_1  1.25301                0.0576645            0.0272676\n",
      "pm10_lag_1  1.02523                0.047182             0.0223108\n",
      "pm25_lag_2  1.01657                0.0467834            0.0221223\n",
      "o3_lag_2    0.889333               0.040928             0.0193535\n",
      "pm10_lag_3  0.87188                0.0401248            0.0189737\n",
      "o3_lag_1    0.787955               0.0362624            0.0171473\n",
      "so2_lag_3   0.627353               0.0288714            0.0136523\n",
      "pm10_lag_2  0.578602               0.0266278            0.0125914\n",
      "so2_lag_2   0.571039               0.0262798            0.0124268\n",
      "pm25_lag_3  0.482804               0.0222191            0.0105067\n",
      "so2_lag_1   0.349839               0.0160999            0.00761311\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OXGBoostEstimator\n",
    "xgb = H2OXGBoostEstimator()\n",
    "xgb.train(x=x, y=y, training_frame=train_h2o)\n",
    "print(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |███████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.154396\n",
      " 0.148283\n",
      " 0.154908\n",
      " 0.235367\n",
      " 0.263488\n",
      " 0.261706\n",
      " 0.263726\n",
      " 0.230798\n",
      " 0.198448\n",
      " 0.160024\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=xgb.predict(test_h2o)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de pred: 162\n",
      "RMSE: 0.12909251349098472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacked Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`H2OStackedEnsembleEstimator` es una clase en H2O que se utiliza para construir modelos de ensamblado apilado (Stacked Ensemble). El ensamblado apilado combina múltiples modelos base (por ejemplo, GBM, Random Forest, GLM) para mejorar la precisión y la robustez del modelo final. Este enfoque suele superar el rendimiento de los modelos individuales.\n",
    "\n",
    "**Parámetros de `H2OStackedEnsembleEstimator`**\n",
    "\n",
    "1. **model_id**: Identificador del modelo. Si no se especifica, se generará uno automáticamente.\n",
    "\n",
    "2. **base_models**: Lista de modelos base que se utilizarán en el ensamblado. Estos modelos deben haber sido entrenados previamente.\n",
    "\n",
    "3. **metalearner_algorithm**: Algoritmo a utilizar para el modelo metalearner. Las opciones incluyen:\n",
    "   - `\"AUTO\"`\n",
    "   - `\"glm\"`\n",
    "   - `\"gbm\"`\n",
    "   - `\"drf\"`\n",
    "   - `\"deeplearning\"`\n",
    "   - `\"xgboost\"`\n",
    "\n",
    "4. **metalearner_nfolds**: Número de pliegues para la validación cruzada del modelo metalearner. El valor predeterminado es 0 (sin validación cruzada).\n",
    "\n",
    "5. **metalearner_fold_assignment**: Método para asignar pliegues en la validación cruzada del modelo metalearner. Las opciones incluyen:\n",
    "   - `\"AUTO\"`\n",
    "   - `\"Random\"`\n",
    "   - `\"Modulo\"`\n",
    "   - `\"Stratified\"`\n",
    "\n",
    "6. **metalearner_params**: Parámetros adicionales para el modelo metalearner.\n",
    "\n",
    "7. **blending_frame**: Conjunto de datos de mezcla para el ensamblado apilado. Si se proporciona, se utilizará en lugar de la validación cruzada para entrenar el modelo metalearner.\n",
    "\n",
    "8. **seed**: Semilla para la generación de números aleatorios, lo que permite la reproducibilidad de los resultados.\n",
    "\n",
    "9. **export_checkpoints_dir**: Directorio para exportar los puntos de control del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble Model Build progress: |██████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
      "Model Key: stacked_ensemble\n",
      "\n",
      "\n",
      "Model Summary for Stacked Ensemble: \n",
      "key                                   value\n",
      "------------------------------------  ----------------\n",
      "Stacking strategy                     cross_validation\n",
      "Number of base models (used / total)  3/3\n",
      "# GBM base models (used / total)      1/1\n",
      "# GLM base models (used / total)      1/1\n",
      "# DRF base models (used / total)      1/1\n",
      "Metalearner algorithm                 GLM\n",
      "Metalearner fold assignment scheme    AUTO\n",
      "Metalearner nfolds                    0\n",
      "Metalearner fold_column\n",
      "Custom metalearner hyperparameters    None\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0036059294933838055\n",
      "RMSE: 0.06004939211502316\n",
      "MAE: 0.04638391025257373\n",
      "RMSLE: 0.04396878578889289\n",
      "Mean Residual Deviance: 0.0036059294933838055\n",
      "R^2: 0.9042839211250202\n",
      "Null degrees of freedom: 643\n",
      "Residual degrees of freedom: 640\n",
      "Null deviance: 24.261530779717244\n",
      "Residual deviance: 2.3222185937391706\n",
      "AIC: -1785.0203245247271\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators import H2OStackedEnsembleEstimator\n",
    "# Definir modelos base con validación cruzada\n",
    "glm_ = H2OGeneralizedLinearEstimator(nfolds=5, fold_assignment=\"Modulo\", keep_cross_validation_predictions=True)\n",
    "glm_.train(x=x, y=y, training_frame=train_h2o)\n",
    "\n",
    "gmb_ = H2OGradientBoostingEstimator(nfolds=5, fold_assignment=\"Modulo\", keep_cross_validation_predictions=True)\n",
    "gmb_.train(x=x, y=y, training_frame=train_h2o)\n",
    "\n",
    "rf_ = H2ORandomForestEstimator(nfolds=5, fold_assignment=\"Modulo\", keep_cross_validation_predictions=True)\n",
    "rf_.train(x=x, y=y, training_frame=train_h2o)\n",
    "\n",
    "# Definir y entrenar el modelo de ensamblado apilado\n",
    "se_ = H2OStackedEnsembleEstimator(model_id=\"stacked_ensemble\", base_models=[glm_, gmb_, rf_])\n",
    "se_.train(x=x, y=y, training_frame=train_h2o)\n",
    "print(se_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.13312\n",
      " 0.148707\n",
      " 0.203247\n",
      " 0.242587\n",
      " 0.274938\n",
      " 0.243709\n",
      " 0.230815\n",
      " 0.216492\n",
      " 0.191647\n",
      " 0.161769\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=se_.predict(test_h2o)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de pred: 162\n",
      "RMSE: 0.12364477116519706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLM con Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator : Generalized Linear Modeling\n",
      "Model Key: GLM_model_python_1737536124574_14\n",
      "\n",
      "\n",
      "GLM Model: summary\n",
      "    family    link      regularization                                 lambda_search                                                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
      "--  --------  --------  ---------------------------------------------  ----------------------------------------------------------------------------  ----------------------------  -----------------------------  ----------------------  ------------------------------------------------------\n",
      "    gaussian  identity  Elastic Net (alpha = 0.5, lambda = 4.069E-4 )  nlambda = 100, lambda.max = 0.2497, lambda.min = 4.069E-4, lambda.1se = -1.0  17                            16                             70                      Key_Frame__upload_a7cf8b83869ab8839ca29b5006a84051.hex\n",
      "\n",
      "ModelMetricsRegressionGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.015219602296702453\n",
      "RMSE: 0.12336775225601888\n",
      "MAE: 0.0962788206348243\n",
      "RMSLE: 0.08958553814393494\n",
      "Mean Residual Deviance: 0.015219602296702453\n",
      "R^2: 0.5960096678124531\n",
      "Null degrees of freedom: 643\n",
      "Residual degrees of freedom: 627\n",
      "Null deviance: 24.261530779717244\n",
      "Residual deviance: 9.80142387907638\n",
      "AIC: -831.6573300683075\n",
      "\n",
      "Scoring History: \n",
      "     timestamp            duration    iteration    lambda    predictors    deviance_train        alpha    iterations    training_rmse        training_deviance     training_mae        training_r2\n",
      "---  -------------------  ----------  -----------  --------  ------------  --------------------  -------  ------------  -------------------  --------------------  ------------------  ------------------\n",
      "     2025-01-22 13:56:11  0.000 sec   1            ,25E0     1             0.03767318439590118   0.5\n",
      "     2025-01-22 13:56:11  0.013 sec   2            ,23E0     2             0.0352830126298934    0.5\n",
      "     2025-01-22 13:56:11  0.019 sec   3            ,21E0     2             0.033241099465133095  0.5\n",
      "     2025-01-22 13:56:11  0.024 sec   4            ,19E0     2             0.03150070936622819   0.5\n",
      "     2025-01-22 13:56:11  0.026 sec   5            ,17E0     3             0.029622874689283468  0.5\n",
      "     2025-01-22 13:56:11  0.027 sec   6            ,16E0     3             0.027786895974474996  0.5\n",
      "     2025-01-22 13:56:11  0.029 sec   7            ,14E0     3             0.026238831952531943  0.5\n",
      "     2025-01-22 13:56:11  0.030 sec   8            ,13E0     3             0.024934286217513094  0.5\n",
      "     2025-01-22 13:56:11  0.032 sec   9            ,12E0     5             0.02379820738028537   0.5\n",
      "     2025-01-22 13:56:11  0.033 sec   10           ,11E0     5             0.022768494609303185  0.5\n",
      "---  ---                  ---         ---          ---       ---           ---                   ---      ---           ---                  ---                   ---                 ---\n",
      "     2025-01-22 13:56:11  0.129 sec   61           ,94E-3    17            0.015235377168413826  0.5\n",
      "     2025-01-22 13:56:11  0.131 sec   62           ,86E-3    17            0.01523248854074209   0.5\n",
      "     2025-01-22 13:56:11  0.132 sec   63           ,78E-3    17            0.015229867018833276  0.5\n",
      "     2025-01-22 13:56:11  0.134 sec   64           ,71E-3    17            0.01522757800821925   0.5\n",
      "     2025-01-22 13:56:11  0.135 sec   65           ,65E-3    17            0.01522559586120684   0.5\n",
      "     2025-01-22 13:56:11  0.137 sec   66           ,59E-3    17            0.015224088604952347  0.5\n",
      "     2025-01-22 13:56:11  0.138 sec   67           ,54E-3    17            0.01522291183330747   0.5\n",
      "     2025-01-22 13:56:11  0.139 sec   68           ,49E-3    17            0.015221770807832368  0.5\n",
      "     2025-01-22 13:56:11  0.142 sec   69           ,45E-3    17            0.015220544683212264  0.5\n",
      "     2025-01-22 13:56:11  0.144 sec   70           ,41E-3    17            0.015219602310151837  0.5      70            0.12336775225601888  0.015219602296702453  0.0962788206348243  0.5960096678124531\n",
      "[70 rows x 13 columns]\n",
      "\n",
      "\n",
      "Variable Importances: \n",
      "variable    relative_importance    scaled_importance    percentage\n",
      "----------  ---------------------  -------------------  ------------\n",
      "so2         0.0820448              1                    0.218627\n",
      "o3          0.0752529              0.917218             0.200529\n",
      "pm25        0.0598947              0.730025             0.159603\n",
      "date        0.038826               0.47323              0.103461\n",
      "so2_lag_1   0.0289673              0.353067             0.0771902\n",
      "pm10_lag_1  0.0190714              0.232451             0.0508202\n",
      "so2_lag_3   0.0171345              0.208843             0.0456589\n",
      "so2_lag_2   0.0112206              0.136762             0.0298999\n",
      "pm25_lag_3  0.010116               0.123299             0.0269565\n",
      "pm25_lag_2  0.00902321             0.109979             0.0240444\n",
      "pm25_lag_1  0.00747102             0.0910603            0.0199083\n",
      "pm10        0.00573328             0.0698798            0.0152776\n",
      "pm10_lag_3  0.00402013             0.0489992            0.0107126\n",
      "o3_lag_1    0.00358171             0.0436555            0.0095443\n",
      "o3_lag_3    0.00244551             0.029807             0.00651663\n",
      "o3_lag_2    0.000468995            0.00571632           0.00124974\n",
      "pm10_lag_2  0                      0                    0\n"
     ]
    }
   ],
   "source": [
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator\n",
    "glm2=H2OGeneralizedLinearEstimator(lambda_search=True)\n",
    "glm2.train(x=x, y=y, training_frame=train_h2o)\n",
    "print(glm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n",
      "  predict\n",
      " 0.107684\n",
      " 0.151365\n",
      " 0.171002\n",
      " 0.23249\n",
      " 0.23659\n",
      " 0.24639\n",
      " 0.195197\n",
      " 0.238678\n",
      " 0.187078\n",
      " 0.1416\n",
      "[162 rows x 1 column]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=glm2.predict(test_h2o)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de pred: 162\n",
      "RMSE: 0.1460092223512251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p3j0t4/.local/lib/python3.10/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "pred = pred.as_data_frame()\n",
    "print(\"Longitud de pred:\", len(pred))\n",
    "\n",
    "# Calcular el error cuadrático medio\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
